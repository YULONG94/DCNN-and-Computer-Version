# 从零开始学习卷积神经网络的笔记（特征和分类篇）
## 特征以及其重要性
+ 其实“特征”这个词的重要性是不言而喻的，可以说任何学习的第一步就得学会特征辨识，因为特征是总结规律的前提，设想一下如果世界上所有的规律都是随机的，那么整个物理数学体系也难以搭建起来，对于机器学习也是一样的，我们希望电脑能够学会寻找规律，第一步就是帮他建立其对特征的敏感度，特征越明显，效果越好。
+ 对于一张图片来说，典型的特征包括纹路，边缘，颜色，亮度等；特诊也可以更具体，比如眼睛，鼻子，总而言之，图片中具有区分于其他图片或者物体的因素都可以认为是有效特征。一个好的特征，需要能够提供信息并且不易受图像噪声影响，同时具有旋转，移动和尺寸不变性（或者说即使一些外界体条件变化了，我们也知道这些因素受环境影响的规律）。

## 分类问题
+ 分类问题一般都是作为机器学习的入门课，尤其在传统的机器学习任务中，分类问题的应用是最直接，效果也是最好的。比如最形象的例子就是决策树，直接对输入进来的物体的各种特征，对物体进行分类。
+ 设计一个好的分类器并不简单，不仅仅需要在训练集上具备高精度，而且还需要防止过拟合现象的产生，由于现实生活中训练数据集和测试数据集往往因为不同原因而产生差异（比如数据可能时效性比较强，比如十年前用来做行人识别的网络用在十年后可能就不适合，因为人们的穿衣风格，道路等的变化还是很明显的），由于这些差异，在训练集上精度很好的网络，可能实际使用的时候效果很差。
## 传统的特征描述
传统采用的特征描述可以分为两种
+ 全局，这类描述方法会定义某个物体的一套用来描述整体的特征，比如描述小轿车车牌的方式：矩形，长宽比为440：140，通常为蓝底白字或者其他颜色，等等，这样描述的方式会忽视物体的细节特征，当物体被遮挡或者其他干扰物，那么就会出现检测错误。
+ 局部，这类描述方法侧重定义物体的细节特征，比如正常人脸检测时候，描述为：两个眼睛，两条眉毛，两个耳朵，一个嘴巴，一个鼻子，即使被部分遮挡，并不影响这些特征的收集。
+ 目前在一般图像处理库（比如OpenCV）中已经包含很多这种算法：HOG [Triggs and Dalal, 2005], SIFT[Lowe, 2004], SURF [Bay et al., 2008], FREAK [Alahi et al., 2012], ORB [Rublee et al., 2011], BRISK [Leutenegger et al., 2011], BRIEF [Calonder et al., 2010], and LIOP [Wang et al., 2011b], 下面列举几个开源经典的。
+ HISTOGRAM OF ORIENTED GRADIENTS (HOG)
+ Scale-invariant Feature Transform (SIFT)
+ Speeded-up Robust Features (SURF)
+ 传统特征描述的缺点
## 机器学习中的分类问题
